import os
import sys
import time
import tempfile
import shutil
import gradio as gr
import cv2
import subprocess
import traceback
import glob
from memory_config import get_optimal_config, get_gpu_memory_info

def initialize_models():
    """åˆå§‹åŒ–æ¨¡å‹"""
    try:
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        time.sleep(2)  # æ¨¡æ‹ŸåŠ è½½æ—¶é—´
        return "âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"

def run_dloral_inference(video_path, prompt="", align_method="adain", process_size=512, upscale=2, vae_encoder_tiled_size=1024):
    """è¿è¡ŒDLoRALæ¨ç†"""
    try:
        # è·å–åŸè§†é¢‘çš„fps
        cap = cv2.VideoCapture(video_path)
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        
        # è·å–åŸè§†é¢‘æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        
        # æ„å»ºå‘½ä»¤
        cmd = [
            "python", "src/test_DLoRAL.py",
            "--pretrained_model_path", "stabilityai/stable-diffusion-2-1-base",
            "--ram_ft_path", "preset/models/DAPE.pth",
            "--ram_path", "preset/models/ram_swin_large_14m.pth",
            "--merge_and_unload_lora", "False",
            "--process_size", str(process_size),
            "--pretrained_model_name_or_path", "stabilityai/stable-diffusion-2-1-base",
            "--vae_encoder_tiled_size", str(vae_encoder_tiled_size),
            "--load_cfr",
            "--pretrained_path", "preset/models/checkpoints/model.pkl",
            "--stages", "1",
            "-i", video_path,
            "-o", "results"
        ]
        
        # è¿è¡Œå‘½ä»¤
        # ä½¿ç”¨ Popen æ‰§è¡Œå‘½ä»¤
        with subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True) as proc:
            for line in proc.stdout:
                # å®æ—¶æ‰“å°æ¯ä¸€è¡Œè¾“å‡º
                print(line, end='')  # æˆ–è€…å†™å…¥æ—¥å¿—æ–‡ä»¶ç­‰
                sys.stdout.flush()   # ç¡®ä¿ç«‹å³è¾“å‡ºï¼ˆå°¤å…¶åœ¨é‡å®šå‘æ—¶æœ‰ç”¨ï¼‰

        # å¯é€‰ï¼šç­‰å¾…å­è¿›ç¨‹ç»“æŸå¹¶è·å–è¿”å›ç 
        return_code = proc.wait()
        
        # æŸ¥æ‰¾è¾“å‡ºè§†é¢‘æ–‡ä»¶ï¼Œä¸ç®¡è¿”å›ç å¦‚ä½•
        output_files = []
        if os.path.exists("results"):
            # æŸ¥æ‰¾ä»¥åŸè§†é¢‘åå‘½åçš„å­æ–‡ä»¶å¤¹
            video_folder = os.path.join("results", video_name)
            if os.path.exists(video_folder):
                # è°ƒç”¨frames_to_videoå‡½æ•°ç”Ÿæˆè§†é¢‘ï¼Œä½¿ç”¨åŸè§†é¢‘çš„fps
                ret = frames_to_video(video_folder, "output_video.mp4", original_fps)
                if ret:
                    output_files.append("output_video.mp4")
            else:
                print(f"æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶å¤¹: {video_folder}")
        
        if output_files:
            # å¦‚æœæˆåŠŸç”Ÿæˆäº†è§†é¢‘æ–‡ä»¶ï¼Œå°±è®¤ä¸ºå¤„ç†æˆåŠŸ
            output_video_path = output_files[-1]
            if os.path.exists(output_video_path):
                print(f"æ‰¾åˆ°è¾“å‡ºè§†é¢‘æ–‡ä»¶: {output_video_path}")
                
                # å°è¯•å°†åŸè§†é¢‘çš„éŸ³é¢‘åˆæˆåˆ°æ–°è§†é¢‘ä¸­
                try:
                    # åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                    temp_audio_path = "temp_audio.aac"
                    
                    # æå–åŸè§†é¢‘çš„éŸ³é¢‘
                    if extract_audio_from_video(video_path, temp_audio_path):
                        # åˆ›å»ºå¸¦éŸ³é¢‘çš„æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
                        final_output_path = "output_video_with_audio.mp4"
                        
                        # åˆå¹¶éŸ³é¢‘åˆ°è§†é¢‘
                        if merge_audio_to_video(output_video_path, temp_audio_path, final_output_path):
                            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                            if os.path.exists(temp_audio_path):
                                os.remove(temp_audio_path)
                            if os.path.exists(output_video_path):
                                os.remove(output_video_path)
                            
                            print(f"éŸ³é¢‘åˆæˆå®Œæˆ: {final_output_path}")
                            return final_output_path, "DLoRALå¤„ç†å®Œæˆï¼ˆå«éŸ³é¢‘ï¼‰ï¼"
                        else:
                            print("éŸ³é¢‘åˆæˆå¤±è´¥ï¼Œè¿”å›æ— éŸ³é¢‘ç‰ˆæœ¬")
                            return output_video_path, "DLoRALå¤„ç†å®Œæˆï¼"
                    else:
                        print("éŸ³é¢‘æå–å¤±è´¥ï¼Œè¿”å›æ— éŸ³é¢‘ç‰ˆæœ¬")
                        return output_video_path, "DLoRALå¤„ç†å®Œæˆï¼"
                        
                except Exception as e:
                    print(f"éŸ³é¢‘å¤„ç†å‡ºé”™: {str(e)}ï¼Œè¿”å›æ— éŸ³é¢‘ç‰ˆæœ¬")
                    return output_video_path, "DLoRALå¤„ç†å®Œæˆï¼"
            else:
                print(f"è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {output_video_path}")
                return None, "è§†é¢‘æ–‡ä»¶ç”Ÿæˆå¤±è´¥"
        else:
            # åªæœ‰åœ¨æ²¡æœ‰ç”Ÿæˆè§†é¢‘æ–‡ä»¶æ—¶æ‰è®¤ä¸ºå¤±è´¥
            if return_code == 0:
                return None, "å¤„ç†å®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶"
            else:
                return None, f"å¤„ç†å¤±è´¥: è¿”å›ç  {return_code}"

        
            
    except Exception as e:
        traceback.print_exc()
        return None, f"è¿è¡ŒDLoRALæ—¶å‡ºé”™: {str(e)}"

def create_web_interface():
    """åˆ›å»ºWebç•Œé¢"""
    
    with gr.Blocks(title="DLoRAL è§†é¢‘è¶…åˆ†è¾¨ç‡") as demo:
        gr.HTML("""
        <div style="text-align: center; font-size: 2.5em; font-weight: bold; margin-bottom: 20px; color: #2c3e50;">
        ğŸ¬ DLoRAL è§†é¢‘è¶…åˆ†è¾¨ç‡
        </div>
        <div style="text-align: center; font-size: 1.2em; color: #7f8c8d; margin-bottom: 30px;">
        ä¸€æ­¥æ‰©æ•£ï¼šç»†èŠ‚ä¸°å¯Œä¸”æ—¶é—´ä¸€è‡´çš„è§†é¢‘è¶…åˆ†è¾¨ç‡
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ è¾“å…¥è®¾ç½®")
                
                # æ¨¡å‹åˆå§‹åŒ–æŒ‰é’®
                init_button = gr.Button("ğŸš€ åˆå§‹åŒ–æ¨¡å‹", variant="primary", size="lg")
                init_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", value="æ¨¡å‹æœªåˆå§‹åŒ–", interactive=False)
                
                # è‡ªåŠ¨é…ç½®æŒ‰é’®
                auto_config_button = gr.Button("âš™ï¸ è‡ªåŠ¨é…ç½®å‚æ•°", variant="secondary", size="sm")
                config_status = gr.Textbox(label="é…ç½®çŠ¶æ€", value="", interactive=False)
                
                # è¾“å…¥è§†é¢‘ - ä¿®å¤å…¼å®¹æ€§é—®é¢˜
                input_video = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                
                # å‚æ•°è®¾ç½®
                with gr.Accordion("âš™ï¸ é«˜çº§å‚æ•°", open=False):
                    prompt = gr.Textbox(label="æç¤ºè¯", value="", placeholder="è¾“å…¥é¢å¤–çš„æç¤ºè¯ï¼ˆå¯é€‰ï¼‰")
                    align_method = gr.Dropdown(
                        choices=["adain", "wavelet", "nofix"], 
                        value="adain", 
                        label="é¢œè‰²æ ¡æ­£æ–¹æ³•"
                    )
                    process_size = gr.Slider(
                        minimum=256, maximum=1024, value=512, step=64,
                        label="å¤„ç†å°ºå¯¸"
                    )
                    upscale = gr.Slider(
                        minimum=2, maximum=8, value=2, step=1,
                        label="è¶…åˆ†å€æ•°"
                    )
                    vae_encoder_tiled_size = gr.Slider(
                        minimum=512, maximum=4096, value=1024, step=512,
                        label="VAEç¼–ç å™¨åˆ†å—å¤§å°ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰"
                    )
                
                # å¤„ç†æŒ‰é’®
                process_button = gr.Button("ğŸ¯ å¼€å§‹å¤„ç†", variant="primary", size="lg")
                
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¥ è¾“å‡ºç»“æœ")
                
                # è¾“å‡ºè§†é¢‘
                output_video = gr.Video(label="å¤„ç†åçš„è§†é¢‘")
                
                # å¤„ç†çŠ¶æ€
                status_text = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
        
        # ä½¿ç”¨è¯´æ˜
        gr.Markdown("### ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. **è‡ªåŠ¨é…ç½®**: ç‚¹å‡»"âš™ï¸ è‡ªåŠ¨é…ç½®å‚æ•°"æ ¹æ®GPUæ˜¾å­˜è‡ªåŠ¨è®¾ç½®æœ€ä¼˜å‚æ•°
        2. **åˆå§‹åŒ–æ¨¡å‹**: é¦–æ¬¡ä½¿ç”¨æˆ–é‡å¯åéœ€è¦å…ˆåˆå§‹åŒ–æ¨¡å‹
        3. **ä¸Šä¼ è§†é¢‘**: æ”¯æŒMP4æ ¼å¼çš„è§†é¢‘æ–‡ä»¶
        4. **è®¾ç½®å‚æ•°**: å¯é€‰æ‹©è°ƒæ•´å¤„ç†å‚æ•°
        5. **å¼€å§‹å¤„ç†**: ç‚¹å‡»å¤„ç†æŒ‰é’®å¼€å§‹è§†é¢‘è¶…åˆ†è¾¨ç‡
        6. **ä¸‹è½½ç»“æœ**: å¤„ç†å®Œæˆåå¯ä¸‹è½½å¢å¼ºåçš„è§†é¢‘
        
        **å†…å­˜ä¼˜åŒ–å‚æ•°**:
        - **VAEç¼–ç å™¨åˆ†å—å¤§å°**: æ§åˆ¶GPUå†…å­˜ä½¿ç”¨ï¼Œæ•°å€¼è¶Šå°å†…å­˜å ç”¨è¶Šå°‘
          - 512: æœ€ä½å†…å­˜å ç”¨ï¼Œé€‚åˆ8GBæ˜¾å­˜
          - 1024: å¹³è¡¡æ¨¡å¼ï¼Œé€‚åˆ12-16GBæ˜¾å­˜
          - 2048: é«˜æ€§èƒ½æ¨¡å¼ï¼Œé€‚åˆ20GB+æ˜¾å­˜
          - 4096: æœ€é«˜æ€§èƒ½ï¼Œé€‚åˆ24GB+æ˜¾å­˜
        
        **æ³¨æ„äº‹é¡¹**:
        - å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œåˆ†è¾¨ç‡
        - å»ºè®®è§†é¢‘åˆ†è¾¨ç‡ä¸è¶…è¿‡1080p
        - å¦‚æœå‡ºç°å†…å­˜ä¸è¶³é”™è¯¯ï¼Œè¯·é™ä½VAEç¼–ç å™¨åˆ†å—å¤§å°
        - å»ºè®®å…ˆä½¿ç”¨è‡ªåŠ¨é…ç½®åŠŸèƒ½è·å–æ¨èå‚æ•°
        - å¤„ç†å®Œæˆåä¼šè‡ªåŠ¨å°†åŸè§†é¢‘çš„éŸ³é¢‘åˆæˆåˆ°æ–°è§†é¢‘ä¸­
        - éœ€è¦ç³»ç»Ÿå®‰è£…ffmpegæ‰èƒ½è¿›è¡ŒéŸ³é¢‘åˆæˆ
        """)
        
        # äº‹ä»¶å¤„ç†
        def auto_configure():
            """è‡ªåŠ¨é…ç½®å‚æ•°"""
            try:
                memory_info, error = get_gpu_memory_info()
                if error:
                    return f"âŒ {error}"
                
                if not memory_info:
                    return "âŒ æœªæ£€æµ‹åˆ°GPU"
                
                gpu = memory_info[0]
                optimal_config = get_optimal_config()
                
                status = f"âœ… è‡ªåŠ¨é…ç½®å®Œæˆ\n"
                status += f"GPU: {gpu['name']}\n"
                status += f"å¯ç”¨æ˜¾å­˜: {gpu['free_gb']:.1f}GB\n"
                status += f"æ¨èé…ç½®: VAEåˆ†å—={optimal_config['vae_encoder_tiled_size']}, "
                status += f"å¤„ç†å°ºå¯¸={optimal_config['process_size']}, "
                status += f"è¶…åˆ†å€æ•°={optimal_config['upscale']}"
                
                return status
            except Exception as e:
                return f"âŒ é…ç½®å¤±è´¥: {str(e)}"
        
        def process_video(video_path, prompt, align_method, process_size, upscale, vae_encoder_tiled_size):
            if video_path is None:
                return None, "è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶"
            
            output_path, message = run_dloral_inference(
                video_path, prompt, align_method, process_size, upscale, vae_encoder_tiled_size
            )
            
            return output_path, message
        
        # ç»‘å®šäº‹ä»¶
        init_button.click(
            fn=initialize_models,
            outputs=init_status
        )
        
        auto_config_button.click(
            fn=auto_configure,
            outputs=config_status
        )
        
        process_button.click(
            fn=process_video,
            inputs=[input_video, prompt, align_method, process_size, upscale, vae_encoder_tiled_size],
            outputs=[output_video, status_text]
        )
    
    return demo

def frames_to_video(frames_folder, output_path, fps=30):
    """Convert frame images in folder to MP4 video"""
    frame_pattern = os.path.join(frames_folder, "frame_*.png")
    frame_files = sorted(glob.glob(frame_pattern))
    if not frame_files:
        print(f"No frame images found in {frames_folder}")
        return False
    first_frame = cv2.imread(frame_files[0])
    if first_frame is None:
        print(f"Cannot read first frame: {frame_files[0]}")
        return False
    height, width, layers = first_frame.shape
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    for i, frame_file in enumerate(frame_files):
        frame = cv2.imread(frame_file)
        if frame is not None:
            video_writer.write(frame)
    video_writer.release()
    print(f"è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_path}, FPS: {fps}, å¸§æ•°: {len(frame_files)}")
    return True

def merge_audio_to_video(video_path, audio_path, output_path):
    """å°†éŸ³é¢‘åˆå¹¶åˆ°è§†é¢‘ä¸­"""
    try:
        # ä½¿ç”¨ffmpegå°†éŸ³é¢‘åˆå¹¶åˆ°è§†é¢‘ä¸­
        cmd = [
            "ffmpeg", "-y",  # -yè¡¨ç¤ºè¦†ç›–è¾“å‡ºæ–‡ä»¶
            "-i", video_path,  # è¾“å…¥è§†é¢‘
            "-i", audio_path,  # è¾“å…¥éŸ³é¢‘
            "-c:v", "copy",    # å¤åˆ¶è§†é¢‘æµ
            "-c:a", "aac",     # éŸ³é¢‘ç¼–ç ä¸ºAAC
            "-shortest",       # ä»¥æœ€çŸ­çš„æµä¸ºå‡†
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"éŸ³é¢‘åˆå¹¶æˆåŠŸ: {output_path}")
            return True
        else:
            print(f"éŸ³é¢‘åˆå¹¶å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"éŸ³é¢‘åˆå¹¶å‡ºé”™: {str(e)}")
        return False

def extract_audio_from_video(video_path, audio_path):
    """ä»è§†é¢‘ä¸­æå–éŸ³é¢‘"""
    try:
        # ä½¿ç”¨ffmpegæå–éŸ³é¢‘
        cmd = [
            "ffmpeg", "-y",  # -yè¡¨ç¤ºè¦†ç›–è¾“å‡ºæ–‡ä»¶
            "-i", video_path,  # è¾“å…¥è§†é¢‘
            "-vn",            # ä¸åŒ…å«è§†é¢‘
            "-acodec", "aac", # éŸ³é¢‘ç¼–ç ä¸ºAAC
            audio_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"éŸ³é¢‘æå–æˆåŠŸ: {audio_path}")
            return True
        else:
            print(f"éŸ³é¢‘æå–å¤±è´¥: {result.stderr}")
            return False
    except Exception as e:
        print(f"éŸ³é¢‘æå–å‡ºé”™: {str(e)}")
        return False

if __name__ == "__main__":
    # åˆ›å»ºWebç•Œé¢
    demo = create_web_interface()
    
    # å¯åŠ¨åº”ç”¨
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True,
        inbrowser=True
    )