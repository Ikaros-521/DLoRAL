import os
import sys
import time
import tempfile
import shutil
import gradio as gr
import cv2
import subprocess
import traceback
from memory_config import get_optimal_config, get_gpu_memory_info

def initialize_models():
    """åˆå§‹åŒ–æ¨¡å‹"""
    try:
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        time.sleep(2)  # æ¨¡æ‹ŸåŠ è½½æ—¶é—´
        return "âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"

def run_dloral_inference(video_path, prompt="", align_method="adain", process_size=512, upscale=2, vae_encoder_tiled_size=1024):
    """è¿è¡ŒDLoRALæ¨ç†"""
    try:
        # æ„å»ºå‘½ä»¤
        cmd = [
            "python", "src/test_DLoRAL.py",
            "--pretrained_model_path", "stabilityai/stable-diffusion-2-1-base",
            "--ram_ft_path", "preset/models/DAPE.pth",
            "--ram_path", "preset/models/ram_swin_large_14m.pth",
            "--merge_and_unload_lora", "False",
            "--process_size", str(process_size),
            "--pretrained_model_name_or_path", "stabilityai/stable-diffusion-2-1-base",
            "--vae_encoder_tiled_size", str(vae_encoder_tiled_size),
            "--load_cfr",
            "--pretrained_path", "preset/models/checkpoints/model.pkl",
            "--stages", "1",
            "-i", video_path,
            "-o", "results"
        ]
        
        # è¿è¡Œå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            # æŸ¥æ‰¾è¾“å‡ºè§†é¢‘æ–‡ä»¶
            output_files = []
            if os.path.exists("results"):
                for file in os.listdir("results"):
                    if file.endswith(".mp4"):
                        output_files.append(os.path.join("results", file))
            
            if output_files:
                return output_files[-1], "DLoRALå¤„ç†å®Œæˆï¼"
            else:
                return None, "å¤„ç†å®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶"
        else:
            print(result.stderr)
            return None, f"å¤„ç†å¤±è´¥: {result.stderr}"
            
    except Exception as e:
        traceback.print_exc()
        return None, f"è¿è¡ŒDLoRALæ—¶å‡ºé”™: {str(e)}"

def create_web_interface():
    """åˆ›å»ºWebç•Œé¢"""
    
    with gr.Blocks(title="DLoRAL è§†é¢‘è¶…åˆ†è¾¨ç‡") as demo:
        gr.HTML("""
        <div style="text-align: center; font-size: 2.5em; font-weight: bold; margin-bottom: 20px; color: #2c3e50;">
        ğŸ¬ DLoRAL è§†é¢‘è¶…åˆ†è¾¨ç‡
        </div>
        <div style="text-align: center; font-size: 1.2em; color: #7f8c8d; margin-bottom: 30px;">
        ä¸€æ­¥æ‰©æ•£ï¼šç»†èŠ‚ä¸°å¯Œä¸”æ—¶é—´ä¸€è‡´çš„è§†é¢‘è¶…åˆ†è¾¨ç‡
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ è¾“å…¥è®¾ç½®")
                
                # æ¨¡å‹åˆå§‹åŒ–æŒ‰é’®
                init_button = gr.Button("ğŸš€ åˆå§‹åŒ–æ¨¡å‹", variant="primary", size="lg")
                init_status = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", value="æ¨¡å‹æœªåˆå§‹åŒ–", interactive=False)
                
                # è‡ªåŠ¨é…ç½®æŒ‰é’®
                auto_config_button = gr.Button("âš™ï¸ è‡ªåŠ¨é…ç½®å‚æ•°", variant="secondary", size="sm")
                config_status = gr.Textbox(label="é…ç½®çŠ¶æ€", value="", interactive=False)
                
                # è¾“å…¥è§†é¢‘ - ä¿®å¤å…¼å®¹æ€§é—®é¢˜
                input_video = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                
                # å‚æ•°è®¾ç½®
                with gr.Accordion("âš™ï¸ é«˜çº§å‚æ•°", open=False):
                    prompt = gr.Textbox(label="æç¤ºè¯", value="", placeholder="è¾“å…¥é¢å¤–çš„æç¤ºè¯ï¼ˆå¯é€‰ï¼‰")
                    align_method = gr.Dropdown(
                        choices=["adain", "wavelet", "nofix"], 
                        value="adain", 
                        label="é¢œè‰²æ ¡æ­£æ–¹æ³•"
                    )
                    process_size = gr.Slider(
                        minimum=256, maximum=1024, value=512, step=64,
                        label="å¤„ç†å°ºå¯¸"
                    )
                    upscale = gr.Slider(
                        minimum=2, maximum=8, value=2, step=1,
                        label="è¶…åˆ†å€æ•°"
                    )
                    vae_encoder_tiled_size = gr.Slider(
                        minimum=512, maximum=4096, value=1024, step=512,
                        label="VAEç¼–ç å™¨åˆ†å—å¤§å°ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰"
                    )
                
                # å¤„ç†æŒ‰é’®
                process_button = gr.Button("ğŸ¯ å¼€å§‹å¤„ç†", variant="primary", size="lg")
                
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¥ è¾“å‡ºç»“æœ")
                
                # è¾“å‡ºè§†é¢‘
                output_video = gr.Video(label="å¤„ç†åçš„è§†é¢‘")
                
                # å¤„ç†çŠ¶æ€
                status_text = gr.Textbox(label="å¤„ç†çŠ¶æ€", interactive=False)
        
        # ä½¿ç”¨è¯´æ˜
        gr.Markdown("### ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. **è‡ªåŠ¨é…ç½®**: ç‚¹å‡»"âš™ï¸ è‡ªåŠ¨é…ç½®å‚æ•°"æ ¹æ®GPUæ˜¾å­˜è‡ªåŠ¨è®¾ç½®æœ€ä¼˜å‚æ•°
        2. **åˆå§‹åŒ–æ¨¡å‹**: é¦–æ¬¡ä½¿ç”¨æˆ–é‡å¯åéœ€è¦å…ˆåˆå§‹åŒ–æ¨¡å‹
        3. **ä¸Šä¼ è§†é¢‘**: æ”¯æŒMP4æ ¼å¼çš„è§†é¢‘æ–‡ä»¶
        4. **è®¾ç½®å‚æ•°**: å¯é€‰æ‹©è°ƒæ•´å¤„ç†å‚æ•°
        5. **å¼€å§‹å¤„ç†**: ç‚¹å‡»å¤„ç†æŒ‰é’®å¼€å§‹è§†é¢‘è¶…åˆ†è¾¨ç‡
        6. **ä¸‹è½½ç»“æœ**: å¤„ç†å®Œæˆåå¯ä¸‹è½½å¢å¼ºåçš„è§†é¢‘
        
        **å†…å­˜ä¼˜åŒ–å‚æ•°**:
        - **VAEç¼–ç å™¨åˆ†å—å¤§å°**: æ§åˆ¶GPUå†…å­˜ä½¿ç”¨ï¼Œæ•°å€¼è¶Šå°å†…å­˜å ç”¨è¶Šå°‘
          - 512: æœ€ä½å†…å­˜å ç”¨ï¼Œé€‚åˆ8GBæ˜¾å­˜
          - 1024: å¹³è¡¡æ¨¡å¼ï¼Œé€‚åˆ12-16GBæ˜¾å­˜
          - 2048: é«˜æ€§èƒ½æ¨¡å¼ï¼Œé€‚åˆ20GB+æ˜¾å­˜
          - 4096: æœ€é«˜æ€§èƒ½ï¼Œé€‚åˆ24GB+æ˜¾å­˜
        
        **æ³¨æ„äº‹é¡¹**:
        - å¤„ç†æ—¶é—´å–å†³äºè§†é¢‘é•¿åº¦å’Œåˆ†è¾¨ç‡
        - å»ºè®®è§†é¢‘åˆ†è¾¨ç‡ä¸è¶…è¿‡1080p
        - å¦‚æœå‡ºç°å†…å­˜ä¸è¶³é”™è¯¯ï¼Œè¯·é™ä½VAEç¼–ç å™¨åˆ†å—å¤§å°
        - å»ºè®®å…ˆä½¿ç”¨è‡ªåŠ¨é…ç½®åŠŸèƒ½è·å–æ¨èå‚æ•°
        """)
        
        # äº‹ä»¶å¤„ç†
        def auto_configure():
            """è‡ªåŠ¨é…ç½®å‚æ•°"""
            try:
                memory_info, error = get_gpu_memory_info()
                if error:
                    return f"âŒ {error}"
                
                if not memory_info:
                    return "âŒ æœªæ£€æµ‹åˆ°GPU"
                
                gpu = memory_info[0]
                optimal_config = get_optimal_config()
                
                status = f"âœ… è‡ªåŠ¨é…ç½®å®Œæˆ\n"
                status += f"GPU: {gpu['name']}\n"
                status += f"å¯ç”¨æ˜¾å­˜: {gpu['free_gb']:.1f}GB\n"
                status += f"æ¨èé…ç½®: VAEåˆ†å—={optimal_config['vae_encoder_tiled_size']}, "
                status += f"å¤„ç†å°ºå¯¸={optimal_config['process_size']}, "
                status += f"è¶…åˆ†å€æ•°={optimal_config['upscale']}"
                
                return status
            except Exception as e:
                return f"âŒ é…ç½®å¤±è´¥: {str(e)}"
        
        def process_video(video_path, prompt, align_method, process_size, upscale, vae_encoder_tiled_size):
            if video_path is None:
                return None, "è¯·å…ˆä¸Šä¼ è§†é¢‘æ–‡ä»¶"
            
            output_path, message = run_dloral_inference(
                video_path, prompt, align_method, process_size, upscale, vae_encoder_tiled_size
            )
            
            return output_path, message
        
        # ç»‘å®šäº‹ä»¶
        init_button.click(
            fn=initialize_models,
            outputs=init_status
        )
        
        auto_config_button.click(
            fn=auto_configure,
            outputs=config_status
        )
        
        process_button.click(
            fn=process_video,
            inputs=[input_video, prompt, align_method, process_size, upscale, vae_encoder_tiled_size],
            outputs=[output_video, status_text]
        )
    
    return demo

if __name__ == "__main__":
    # åˆ›å»ºWebç•Œé¢
    demo = create_web_interface()
    
    # å¯åŠ¨åº”ç”¨
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True,
        inbrowser=True
    ) 